{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b3f579",
   "metadata": {},
   "source": [
    "# Fashion Store Email Processor - README\n",
    "\n",
    "## Overview\n",
    "This Jupyter notebook is a comprehensive AI-powered email processing system designed for fashion retail stores. It automatically classifies customer emails, processes orders with inventory management, and generates professional responses using advanced AI techniques including Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), and vector databases.\n",
    "\n",
    "## Features\n",
    "- **Email Classification**: Automatically categorizes emails as \"product inquiry\" or \"order request\"\n",
    "- **Order Processing**: Extracts order details, validates inventory, and updates stock levels\n",
    "- **AI-Powered Responses**: Generates professional responses using OpenAI GPT-4o\n",
    "- **RAG Implementation**: Uses ChromaDB vector store for contextual product information retrieval\n",
    "- **Inventory Management**: Real-time stock tracking and validation\n",
    "- **Google Sheets Integration**: Loads data from Google Spreadsheets and exports results\n",
    "- **Robust Error Handling**: Comprehensive fallback mechanisms and validation\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### Required API Keys\n",
    "- **OpenAI API Key**: Required for GPT-4o model access\n",
    "  - Get your key from: https://platform.openai.com/api-keys\n",
    "  - Set in Google Colab Secrets as `OPENAI_API_KEY` or as environment variable\n",
    "\n",
    "### Data Source\n",
    "- Google Spreadsheet with the following sheets:\n",
    "  - `products`: Product catalog (ID, Name, Description, Price, Stock)\n",
    "  - `emails`: Customer emails to process (ID, From, Subject, Body)\n",
    "- Default spreadsheet ID: `14fKHsblfqZfWj3iAaM2oA51TlYfQlFT4WKo52fVaQ9U`\n",
    "\n",
    "## Installation & Setup\n",
    "\n",
    "### 1. Google Colab (Recommended)\n",
    "1. Open this notebook in Google Colab\n",
    "2. Run the package installation cell (all dependencies will be installed automatically)\n",
    "3. Set your OpenAI API key in Colab Secrets:\n",
    "   - Go to the key icon (ðŸ”‘) in the left sidebar\n",
    "   - Add secret: Name = `OPENAI_API_KEY`, Value = your API key\n",
    "4. Run all cells sequentially\n",
    "\n",
    "### 2. Local Jupyter Environment\n",
    "1. Install required packages:\n",
    "```bash\n",
    "pip install pandas numpy openai langchain langchain-openai langchain-chroma chromadb gspread oauth2client openpyxl xlsxwriter\n",
    "```\n",
    "2. Set environment variable:\n",
    "```bash\n",
    "export OPENAI_API_KEY=\"your-api-key-here\"\n",
    "```\n",
    "3. For Google Sheets access, you'll need to set up authentication credentials\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Quick Start\n",
    "1. Ensure your OpenAI API key is configured\n",
    "2. Run all cells in order (Runtime â†’ Run all in Colab)\n",
    "3. The system will:\n",
    "   - Load data from the Google Spreadsheet\n",
    "   - Process all emails automatically\n",
    "   - Generate an Excel output file with results\n",
    "\n",
    "### Output\n",
    "The notebook generates a comprehensive Excel file (`fashion_store_results_YYYYMMDD_HHMMSS.xlsx`) with four sheets:\n",
    "- **email-classification**: Email categories and confidence scores\n",
    "- **order-status**: Order processing results and inventory updates\n",
    "- **order-response**: AI-generated responses for order emails\n",
    "- **inquiry-response**: AI-generated responses for product inquiries\n",
    "\n",
    "### Customization\n",
    "- **Change data source**: Modify `SPREADSHEET_ID` variable\n",
    "- **Adjust AI models**: Update model names in OpenAI initialization\n",
    "- **Modify prompts**: Edit classification and response generation prompts\n",
    "- **Update product catalog**: Add/modify products in the Google Spreadsheet\n",
    "\n",
    "## Architecture\n",
    "\n",
    "### Core Components\n",
    "1. **Data Loading**: Google Sheets API integration with CSV fallback\n",
    "2. **AI Classification**: LLM-based email categorization with keyword fallback\n",
    "3. **Vector Store**: ChromaDB for product catalog embeddings\n",
    "4. **Order Processing**: Advanced parsing with quantity validation and inventory management\n",
    "5. **Response Generation**: RAG-enhanced professional email responses\n",
    "6. **Output Management**: Multi-sheet Excel export with comprehensive results\n",
    "\n",
    "### AI Technologies Used\n",
    "- **OpenAI GPT-4o**: Email classification and response generation\n",
    "- **LangChain**: LLM orchestration and prompt management\n",
    "- **ChromaDB**: Vector database for similarity search\n",
    "- **Embeddings**: Product catalog vectorization for RAG\n",
    "\n",
    "## Error Handling & Fallbacks\n",
    "- **API Failures**: Graceful degradation with template responses\n",
    "- **Data Loading**: Multiple authentication methods and CSV fallback\n",
    "- **Quantity Parsing**: Advanced NLP for various quantity formats\n",
    "- **Product Matching**: Fuzzy matching with similarity scoring\n",
    "- **Inventory Validation**: Real-time stock checking and updates\n",
    "\n",
    "## Performance Notes\n",
    "- Processes emails sequentially for consistent results\n",
    "- Uses efficient vector similarity search for product queries\n",
    "- Optimized for Google Colab environment\n",
    "- Handles large datasets with memory-efficient processing\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Common Issues\n",
    "1. **\"OpenAI API key not found\"**: Set the API key in Colab Secrets or environment variables\n",
    "2. **Google Sheets access denied**: Check spreadsheet permissions (must be publicly readable)\n",
    "3. **ChromaDB warnings**: Normal telemetry messages (can be ignored)\n",
    "4. **Memory issues**: Restart runtime and run cells sequentially\n",
    "\n",
    "### Debug Features\n",
    "- Status check cells for environment validation\n",
    "- Detailed logging throughout processing\n",
    "- Preview cells for data verification\n",
    "- Error tracking and reporting\n",
    "\n",
    "## File Structure\n",
    "```\n",
    "fashion_store_email_processor.ipynb    # Main notebook\n",
    "â”œâ”€â”€ Package Installation               # Colab-optimized setup\n",
    "â”œâ”€â”€ Data Loading & Authentication     # Google Sheets integration\n",
    "â”œâ”€â”€ AI Model Initialization          # OpenAI and LangChain setup\n",
    "â”œâ”€â”€ Email Classification             # LLM-based categorization\n",
    "â”œâ”€â”€ Order Processing                 # Inventory management\n",
    "â”œâ”€â”€ Response Generation              # AI-powered replies\n",
    "â””â”€â”€ Output & Export                  # Excel file generation\n",
    "```\n",
    "\n",
    "## Contributing\n",
    "This notebook follows best practices for:\n",
    "- Code documentation and comments\n",
    "- Error handling and validation\n",
    "- Modular function design\n",
    "- Clear output formatting\n",
    "- User-friendly progress indicators\n",
    "\n",
    "## License\n",
    "This project is designed for educational and commercial use in fashion retail automation.\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to get started?** Run the cells below to begin processing your fashion store emails!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eabdf6a",
   "metadata": {},
   "source": [
    "# ðŸ›ï¸ Fashion Store Email Processing System\n",
    "## Intelligent Email Order Processing and Customer Inquiry Handler\n",
    "\n",
    "**Objective:** Develop a proof-of-concept application to intelligently process email order requests and customer inquiries for a fashion store using advanced AI techniques.\n",
    "\n",
    "### ðŸŽ¯ Key Requirements:\n",
    "1. **Email Classification**: Categorize emails as \"product inquiry\" or \"order request\"\n",
    "2. **Order Processing**: Handle order requests with inventory management\n",
    "3. **Response Generation**: Create professional responses using RAG techniques\n",
    "4. **Product Inquiries**: Respond to customer questions using product catalog\n",
    "\n",
    "### ðŸ§  AI Techniques Used:\n",
    "- **Large Language Models (LLMs)**: GPT-4o for natural language understanding\n",
    "- **Retrieval-Augmented Generation (RAG)**: Context-aware response generation\n",
    "- **Vector Stores**: ChromaDB for semantic product search\n",
    "- **Advanced Prompting**: Structured prompts for accurate classification and extraction\n",
    "\n",
    "### ðŸ“‹ Expected Outputs:\n",
    "- `email-classification`: Email ID, Category\n",
    "- `order-status`: Email ID, Product ID, Quantity, Status\n",
    "- `order-response`: Email ID, Response\n",
    "- `inquiry-response`: Email ID, Response\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3b780",
   "metadata": {},
   "source": [
    "## ðŸ“š Section 1: Import Required Libraries\n",
    "\n",
    "Import all necessary libraries for data processing, LLM interaction, vector storage, and spreadsheet handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56807110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Google Colab\n",
    "# Note: In Colab, use !pip install instead of subprocess for better compatibility\n",
    "\n",
    "print(\"ðŸ”„ Installing required packages for Google Colab...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Install packages using Colab's native pip installation\n",
    "!pip install -q openai>=1.0.0\n",
    "!pip install -q langchain>=0.1.0\n",
    "!pip install -q langchain-openai>=0.1.0\n",
    "!pip install -q langchain-core>=0.1.0\n",
    "!pip install -q chromadb>=0.4.0\n",
    "!pip install -q pandas>=1.5.0\n",
    "!pip install -q numpy>=1.24.0\n",
    "!pip install -q openpyxl>=3.1.0\n",
    "!pip install -q tiktoken>=0.5.0\n",
    "!pip install -q gspread>=5.0.0\n",
    "!pip install -q google-auth>=2.0.0\n",
    "\n",
    "print(\"ðŸŽ‰ Package installation complete!\")\n",
    "print(\"ðŸ“ Note: Restart runtime if you encounter import issues (Runtime â†’ Restart runtime)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09ea902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# OpenAI and LangChain for LLM functionality\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "\n",
    "# LangChain components for advanced AI workflows\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Vector store and RAG components\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Google Sheets integration (with Colab authentication support)\n",
    "try:\n",
    "    import gspread\n",
    "    from google.auth import default\n",
    "    from google.colab import auth\n",
    "    GSHEETS_AVAILABLE = True\n",
    "    COLAB_ENV = True\n",
    "    print(\"ðŸ“± Running in Google Colab environment\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        import gspread\n",
    "        from google.auth import default\n",
    "        GSHEETS_AVAILABLE = True\n",
    "        COLAB_ENV = False\n",
    "        print(\"ðŸ’» Running in local environment\")\n",
    "    except ImportError:\n",
    "        GSHEETS_AVAILABLE = False\n",
    "        COLAB_ENV = False\n",
    "        print(\"âš ï¸ Google Sheets libraries not available. Will use local CSV files.\")\n",
    "\n",
    "# Additional utilities\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"ðŸ“Š Pandas version: {pd.__version__}\")\n",
    "print(f\"ðŸ§  OpenAI library available\")\n",
    "print(f\"ðŸ”— LangChain components loaded\")\n",
    "print(f\"ðŸ—„ï¸ ChromaDB available for vector storage\")\n",
    "print(f\"ðŸ“‘ Google Sheets support: {GSHEETS_AVAILABLE}\")\n",
    "print(f\"ðŸŒ Colab environment: {COLAB_ENV}\")\n",
    "print(\"\\nðŸš€ Ready to process fashion store emails with AI!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ee8844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab Authentication (run this cell if using Colab for Google Sheets access)\n",
    "if COLAB_ENV and GSHEETS_AVAILABLE:\n",
    "    print(\"ðŸ” Authenticating with Google Sheets in Colab...\")\n",
    "    try:\n",
    "        auth.authenticate_user()\n",
    "        print(\"âœ… Google authentication successful!\")\n",
    "        print(\"ðŸ“ You can now access Google Sheets from this Colab session\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Authentication failed: {e}\")\n",
    "        print(\"ðŸ’¡ You can still use the public CSV export method as fallback\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ Skipping Colab authentication (not in Colab environment or gspread not available)\")\n",
    "    print(\"ðŸ“„ Will use public CSV export method for Google Sheets access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eefdff",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Section 2: Load Spreadsheet Data\n",
    "\n",
    "Load the Google Spreadsheet containing product catalog and email data. We'll use the provided document ID to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Spreadsheet configuration\n",
    "DOCUMENT_ID = '14fKHsblfqZfWj3iAaM2oA51TlYfQlFT4WKo52fVaQ9U'  # From the assessment\n",
    "\n",
    "def load_sheet_data(document_id: str, sheet_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load data from Google Sheets using the public CSV export URL.\n",
    "    \n",
    "    Args:\n",
    "        document_id (str): Google Sheets document ID\n",
    "        sheet_name (str): Name of the sheet to load\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Construct public CSV export URL\n",
    "        export_url = f\"https://docs.google.com/spreadsheets/d/{document_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "        \n",
    "        logger.info(f\"Loading sheet '{sheet_name}' from Google Sheets...\")\n",
    "        df = pd.read_csv(export_url)\n",
    "        \n",
    "        logger.info(f\"âœ… Loaded {len(df)} rows and {len(df.columns)} columns from '{sheet_name}'\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"âŒ Failed to load sheet '{sheet_name}': {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Load product catalog and emails data\n",
    "try:\n",
    "    # Load products data\n",
    "    logger.info(\"ðŸ“¦ Loading product catalog...\")\n",
    "    products_df = load_sheet_data(DOCUMENT_ID, 'products')\n",
    "    \n",
    "    # Load emails data  \n",
    "    logger.info(\"ðŸ“§ Loading emails data...\")\n",
    "    emails_df = load_sheet_data(DOCUMENT_ID, 'emails')\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ Data loaded successfully!\")\n",
    "    print(f\"ðŸ“¦ Products: {len(products_df)} items\")\n",
    "    print(f\"ðŸ“§ Emails: {len(emails_df)} messages\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load data: {e}\")\n",
    "    # Fallback: Create sample data for testing\n",
    "    print(\"âš ï¸ Creating sample data for testing...\")\n",
    "    \n",
    "    products_df = pd.DataFrame({\n",
    "        'product_id': ['P001', 'P002', 'P003'],\n",
    "        'name': ['Summer Dress', 'Winter Coat', 'Casual Jeans'],\n",
    "        'category': ['Dresses', 'Outerwear', 'Pants'],\n",
    "        'stock': [10, 5, 15],\n",
    "        'description': [\n",
    "            'Lightweight cotton summer dress perfect for warm weather',\n",
    "            'Warm winter coat with waterproof material',\n",
    "            'Comfortable casual jeans made from denim'\n",
    "        ],\n",
    "        'seasons': ['Summer', 'Winter', 'All Season'],\n",
    "        'price': [49.99, 129.99, 79.99]\n",
    "    })\n",
    "    \n",
    "    emails_df = pd.DataFrame({\n",
    "        'email_id': ['E001', 'E002'],\n",
    "        'subject': ['Product Question', 'Order Request'],\n",
    "        'message': [\n",
    "            'Do you have summer dresses available?',\n",
    "            'I would like to order 2 summer dresses.'\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Add consistent column names\n",
    "    emails_df['email_content'] = emails_df['message']\n",
    "    emails_df['customer_email'] = emails_df['email_id'].apply(lambda x: f\"customer_{x}@example.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a31c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data for verification\n",
    "print(\"ðŸ“¦ PRODUCTS SAMPLE:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Columns: {list(products_df.columns)}\")\n",
    "print(\"\\nFirst 5 products:\")\n",
    "display(products_df.head())\n",
    "\n",
    "print(\"\\nðŸ“§ EMAILS SAMPLE:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Columns: {list(emails_df.columns)}\")\n",
    "print(\"\\nFirst 5 emails:\")\n",
    "display(emails_df.head())\n",
    "\n",
    "# Data validation and preprocessing\n",
    "print(\"\\nðŸ” DATA VALIDATION:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in products:\")\n",
    "print(products_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in emails:\")\n",
    "print(emails_df.isnull().sum())\n",
    "\n",
    "# Ensure stock amounts are numeric\n",
    "if 'stock' in products_df.columns:\n",
    "    products_df['stock'] = pd.to_numeric(products_df['stock'], errors='coerce').fillna(0)\n",
    "\n",
    "# Clean email data - handle both possible column names\n",
    "if 'subject' in emails_df.columns:\n",
    "    emails_df['subject'] = emails_df['subject'].fillna('')\n",
    "if 'message' in emails_df.columns:\n",
    "    emails_df['message'] = emails_df['message'].fillna('')\n",
    "    # Create a consistent column name for email content\n",
    "    emails_df['email_content'] = emails_df['message']\n",
    "elif 'body' in emails_df.columns:\n",
    "    emails_df['body'] = emails_df['body'].fillna('')\n",
    "    emails_df['email_content'] = emails_df['body']\n",
    "\n",
    "# Ensure we have the required columns with consistent names\n",
    "if 'customer_email' not in emails_df.columns:\n",
    "    emails_df['customer_email'] = emails_df['email_id'].apply(lambda x: f\"customer_{x}@example.com\")\n",
    "\n",
    "print(f\"\\nâœ… Data validation complete!\")\n",
    "print(f\"ðŸ“¦ Products ready: {len(products_df)} items\")\n",
    "print(f\"ðŸ“§ Emails ready: {len(emails_df)} messages\")\n",
    "print(f\"ðŸ“‹ Email columns: {list(emails_df.columns)}\")\n",
    "print(f\"ðŸ“‹ Product columns: {list(products_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d52574a",
   "metadata": {},
   "source": [
    "## ðŸ§  Section 3: Set Up OpenAI API and Vector Store\n",
    "\n",
    "Configure OpenAI API and initialize ChromaDB vector store for product catalog embeddings to enable RAG functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e29b9c",
   "metadata": {},
   "source": [
    "### ðŸ”‘ Setting up API Keys in Google Colab\n",
    "\n",
    "For better security and flexibility, you can set up your OpenAI API key using Colab's secrets feature:\n",
    "\n",
    "1. **Using Colab Secrets (Recommended):**\n",
    "   - Click on the key icon (ðŸ”‘) in the left sidebar\n",
    "   - Add a new secret named `OPENAI_API_KEY`\n",
    "   - Enter your OpenAI API key value\n",
    "   - Toggle on \"Notebook access\" for this secret\n",
    "\n",
    "2. **Alternative: Set environment variable in a cell:**\n",
    "   ```python\n",
    "   import os\n",
    "   os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\n",
    "   ```\n",
    "\n",
    "3. **The notebook will automatically detect and use your API key from these sources**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a343d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Configuration\n",
    "# For Google Colab: Use secrets or environment variables for better security\n",
    "\n",
    "import os\n",
    "\n",
    "# Option 1: Use Colab secrets (recommended for Colab)\n",
    "OPENAI_API_KEY = None\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    try:\n",
    "        OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "        print(\"ðŸ” Using OpenAI API key from Colab secrets\")\n",
    "    except Exception as secret_error:\n",
    "        print(f\"â„¹ï¸ Colab secret 'OPENAI_API_KEY' not found: {secret_error}\")\n",
    "        print(\"ðŸ’¡ To set up: Click the key icon (ðŸ”‘) in the left sidebar â†’ Add secret 'OPENAI_API_KEY'\")\n",
    "except ImportError:\n",
    "    print(\"ðŸ’» Not running in Colab environment\")\n",
    "\n",
    "# Option 2: Use environment variable (for local environments)\n",
    "if not OPENAI_API_KEY:\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "    if OPENAI_API_KEY:\n",
    "        print(\"ðŸ” Using OpenAI API key from environment variable\")\n",
    "\n",
    "# Option 3: Fallback to provided temporary key (for testing)\n",
    "if not OPENAI_API_KEY:\n",
    "    OPENAI_API_KEY = 'a0BIj000002vVUoMAM'  # Provided temporary key\n",
    "    print(\"âš ï¸ Using provided temporary API key for testing\")\n",
    "    print(\"ðŸ’¡ For your own projects, set up your OpenAI API key in Colab secrets or environment variables\")\n",
    "\n",
    "OPENAI_BASE_URL = 'https://47v4us7kyypinfb5lcligtc3x40ygqbs.lambda-url.us-east-1.on.aws/v1/'\n",
    "OPENAI_MODEL = \"gpt-4o\"\n",
    "\n",
    "print(f\"ðŸ”§ OpenAI Configuration:\")\n",
    "print(f\"   Model: {OPENAI_MODEL}\")\n",
    "print(f\"   Base URL: {OPENAI_BASE_URL}\")\n",
    "print(f\"   API Key: {'***' + OPENAI_API_KEY[-4:] if OPENAI_API_KEY else 'Not set'}\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "try:\n",
    "    openai_client = OpenAI(\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        base_url=OPENAI_BASE_URL\n",
    "    )\n",
    "    \n",
    "    # Test the connection\n",
    "    test_response = openai_client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Test connection\"}],\n",
    "        max_tokens=5\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… OpenAI client initialized successfully!\")\n",
    "    print(f\"ðŸŽ¯ Model: {OPENAI_MODEL}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"âŒ Failed to initialize OpenAI client: {e}\")\n",
    "    raise\n",
    "\n",
    "# Initialize LangChain components\n",
    "try:\n",
    "    # LangChain ChatOpenAI instance\n",
    "    llm = ChatOpenAI(\n",
    "        model=OPENAI_MODEL,\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        base_url=OPENAI_BASE_URL,\n",
    "        temperature=0.1,  # Low temperature for consistent results\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    # Embeddings for vector store\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        base_url=OPENAI_BASE_URL\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… LangChain components initialized!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"âŒ Failed to initialize LangChain: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5cbc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChromaDB Vector Store\n",
    "def setup_vector_store():\n",
    "    \"\"\"Set up ChromaDB vector store for product catalog.\"\"\"\n",
    "    try:\n",
    "        # Initialize ChromaDB client with telemetry disabled to avoid warnings\n",
    "        import chromadb\n",
    "        from chromadb.config import Settings\n",
    "        \n",
    "        chroma_client = chromadb.Client(Settings(\n",
    "            anonymized_telemetry=False\n",
    "        ))\n",
    "        \n",
    "        # Create or get collection for products\n",
    "        collection_name = \"fashion_products\"\n",
    "        \n",
    "        # Delete existing collection if it exists (for fresh start)\n",
    "        try:\n",
    "            chroma_client.delete_collection(collection_name)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        collection = chroma_client.create_collection(\n",
    "            name=collection_name,\n",
    "            metadata={\"description\": \"Fashion store product catalog\"}\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"âœ… ChromaDB collection '{collection_name}' created\")\n",
    "        return chroma_client, collection\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"âŒ Failed to setup vector store: {e}\")\n",
    "        raise\n",
    "\n",
    "# Set up vector store\n",
    "chroma_client, product_collection = setup_vector_store()\n",
    "\n",
    "# Embed product catalog for RAG\n",
    "def embed_product_catalog(products_df: pd.DataFrame, collection):\n",
    "    \"\"\"\n",
    "    Create embeddings for product catalog and store in ChromaDB.\n",
    "    \n",
    "    Args:\n",
    "        products_df (pd.DataFrame): Product catalog\n",
    "        collection: ChromaDB collection\n",
    "    \"\"\"\n",
    "    logger.info(\"ðŸ”„ Creating product embeddings...\")\n",
    "    \n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "    \n",
    "    for idx, product in products_df.iterrows():\n",
    "        # Create rich product description for embedding\n",
    "        product_text = f\"\"\"\n",
    "        Product: {product.get('name', '')}\n",
    "        Category: {product.get('category', '')}\n",
    "        Description: {product.get('description', '')}\n",
    "        Season: {product.get('seasons', '')}\n",
    "        Stock: {product.get('stock', 0)} units available\n",
    "        Price: ${product.get('price', 0)}\n",
    "        Product ID: {product.get('product_id', '')}\n",
    "        \"\"\".strip()\n",
    "        \n",
    "        documents.append(product_text)\n",
    "        \n",
    "        # Store metadata for retrieval\n",
    "        metadatas.append({\n",
    "            'product_id': str(product.get('product_id', '')),\n",
    "            'name': str(product.get('name', '')),\n",
    "            'category': str(product.get('category', '')),\n",
    "            'stock': int(product.get('stock', 0)),\n",
    "            'seasons': str(product.get('seasons', '')),\n",
    "            'description': str(product.get('description', '')),\n",
    "            'price': float(product.get('price', 0))\n",
    "        })\n",
    "        \n",
    "        ids.append(f\"product_{idx}\")\n",
    "    \n",
    "    # Add documents to collection\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"âœ… Embedded {len(documents)} products in vector store\")\n",
    "    return len(documents)\n",
    "\n",
    "# Embed the product catalog\n",
    "num_embedded = embed_product_catalog(products_df, product_collection)\n",
    "print(f\"ðŸŽ‰ Vector store ready with {num_embedded} product embeddings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c975ca",
   "metadata": {},
   "source": [
    "## ðŸ“§ Section 4: Email Classification\n",
    "\n",
    "Classify each email as either \"product inquiry\" or \"order request\" using advanced LLM prompting techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddab3254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify emails using OpenAI LLM\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "# Ensure LLM is properly initialized with robust error handling\n",
    "llm_available = False\n",
    "\n",
    "try:\n",
    "    # Test if llm is already defined and working\n",
    "    if 'llm' in globals() and llm is not None:\n",
    "        test_response = llm.invoke([HumanMessage(content=\"test\")])\n",
    "        print(\"âœ… LLM is ready for classification\")\n",
    "        llm_available = True\n",
    "    else:\n",
    "        raise NameError(\"LLM not defined\")\n",
    "        \n",
    "except (NameError, Exception) as e:\n",
    "    print(f\"âš ï¸ LLM issue detected: {e}\")\n",
    "    print(\"ðŸ”„ Attempting to initialize LLM...\")\n",
    "    \n",
    "    try:\n",
    "        # Reinitialize OpenAI and LangChain\n",
    "        if 'OPENAI_API_KEY' not in globals():\n",
    "            # Reinitialize OpenAI settings if needed\n",
    "            OPENAI_API_KEY = 'a0BIj000002vVUoMAM'\n",
    "            OPENAI_BASE_URL = 'https://47v4us7kyypinfb5lcligtc3x40ygqbs.lambda-url.us-east-1.on.aws/v1/'\n",
    "            OPENAI_MODEL = \"gpt-4o\"\n",
    "        \n",
    "        # Reinitialize LangChain ChatOpenAI instance\n",
    "        llm = ChatOpenAI(\n",
    "            model=OPENAI_MODEL,\n",
    "            api_key=OPENAI_API_KEY,\n",
    "            base_url=OPENAI_BASE_URL,\n",
    "            temperature=0.1,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        \n",
    "        # Test the LLM\n",
    "        test_response = llm.invoke([HumanMessage(content=\"test\")])\n",
    "        print(\"âœ… LLM reinitialized and tested successfully\")\n",
    "        llm_available = True\n",
    "        \n",
    "    except Exception as init_error:\n",
    "        print(f\"âŒ Failed to initialize LLM: {init_error}\")\n",
    "        print(\"ðŸ“‹ Will use keyword-based classification fallback\")\n",
    "        llm = None\n",
    "        llm_available = False\n",
    "\n",
    "print(f\"ðŸŽ¯ LLM Status: {'Available' if llm_available else 'Unavailable (using fallback)'}\")\n",
    "\n",
    "def classify_email(email_content):\n",
    "    \"\"\"\n",
    "    Classify an email as 'product inquiry' or 'order request' using GPT-4o or fallback method\n",
    "    \"\"\"\n",
    "    # First try LLM classification if available\n",
    "    if llm_available and llm is not None:\n",
    "        try:\n",
    "            system_prompt = \"\"\"You are an AI assistant for a fashion store email classification system.\n",
    "            Your task is to classify customer emails into exactly one of these two categories:\n",
    "            - \"product inquiry\": emails asking about product details, availability, recommendations, styling advice, etc.\n",
    "            - \"order request\": emails expressing intent to purchase, place orders, or asking about ordering process\n",
    "            \n",
    "            Respond with ONLY the classification category - either \"product inquiry\" or \"order request\".\n",
    "            Be precise and consistent in your classification.\"\"\"\n",
    "            \n",
    "            human_prompt = f\"Classify this customer email:\\n\\n{email_content}\"\n",
    "            \n",
    "            messages = [\n",
    "                SystemMessage(content=system_prompt),\n",
    "                HumanMessage(content=human_prompt)\n",
    "            ]\n",
    "            \n",
    "            response = llm.invoke(messages)\n",
    "            classification = response.content.strip().lower()\n",
    "            \n",
    "            # Ensure we return a valid classification\n",
    "            if \"product inquiry\" in classification:\n",
    "                return \"product inquiry\"\n",
    "            elif \"order request\" in classification:\n",
    "                return \"order request\"\n",
    "            else:\n",
    "                # If LLM response is unclear, fall through to keyword-based method\n",
    "                print(f\"âš ï¸ Unclear LLM response: {classification}, using fallback\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ LLM classification error: {e}, using fallback\")\n",
    "    \n",
    "    # Fallback: keyword-based classification\n",
    "    print(\"ðŸ“‹ Using keyword-based classification fallback\")\n",
    "    \n",
    "    order_keywords = ['buy', 'purchase', 'order', 'checkout', 'payment', 'shipping', 'place order', 'want to buy']\n",
    "    inquiry_keywords = ['recommend', 'advice', 'available', 'details', 'size', 'color', 'information', 'tell me about']\n",
    "    \n",
    "    email_lower = email_content.lower()\n",
    "    \n",
    "    # Score based on keyword presence\n",
    "    order_score = sum(1 for keyword in order_keywords if keyword in email_lower)\n",
    "    inquiry_score = sum(1 for keyword in inquiry_keywords if keyword in email_lower)\n",
    "    \n",
    "    # Default to order request if more order keywords, otherwise product inquiry\n",
    "    if order_score > inquiry_score:\n",
    "        return \"order request\"\n",
    "    elif inquiry_score > 0:\n",
    "        return \"product inquiry\"\n",
    "    else:\n",
    "        # If no clear keywords, check for action words\n",
    "        action_words = ['i want', 'i need', 'can i get', 'please send']\n",
    "        if any(action in email_lower for action in action_words):\n",
    "            return \"order request\"\n",
    "        else:\n",
    "            return \"product inquiry\"\n",
    "\n",
    "# Apply classification to all emails\n",
    "print(\"Classifying emails...\")\n",
    "emails_df['classification'] = emails_df['email_content'].apply(classify_email)\n",
    "\n",
    "# Display classification results\n",
    "print(f\"\\nClassification Results:\")\n",
    "print(f\"Total emails: {len(emails_df)}\")\n",
    "print(f\"Product inquiries: {len(emails_df[emails_df['classification'] == 'product inquiry'])}\")\n",
    "print(f\"Order requests: {len(emails_df[emails_df['classification'] == 'order request'])}\")\n",
    "\n",
    "# Show sample classifications\n",
    "print(f\"\\nSample Classifications:\")\n",
    "for idx, row in emails_df.head().iterrows():\n",
    "    print(f\"Email {idx + 1}: {row['classification']}\")\n",
    "    print(f\"Content preview: {row['email_content'][:100]}...\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ed49ca",
   "metadata": {},
   "source": [
    "## ðŸ›’ Section 5: Process Order Requests and Update Stock\n",
    "\n",
    "This section processes emails classified as \"order request\", extracts order information using LLM, checks product availability, updates inventory, and records order status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa53b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process order requests and manage inventory\n",
    "import json\n",
    "\n",
    "def extract_order_info(email_content):\n",
    "    \"\"\"\n",
    "    Extract order information from email using LLM or fallback parsing\n",
    "    Returns a structured dictionary with product requests\n",
    "    \"\"\"\n",
    "    # Try LLM extraction if available\n",
    "    if llm_available and llm is not None:\n",
    "        try:\n",
    "            system_prompt = \"\"\"You are an AI assistant that extracts order information from customer emails.\n",
    "            \n",
    "            Extract the following information and return it as a valid JSON object ONLY (no additional text):\n",
    "            {\n",
    "                \"products\": [\n",
    "                    {\n",
    "                        \"product_name\": \"exact product name or product code mentioned (e.g., LTH0976, VBT2345)\",\n",
    "                        \"quantity\": number_requested,\n",
    "                        \"size\": \"size if mentioned, otherwise null\",\n",
    "                        \"color\": \"color if mentioned, otherwise null\"\n",
    "                    }\n",
    "                ],\n",
    "                \"customer_preferences\": \"any specific preferences or requirements\"\n",
    "            }\n",
    "            \n",
    "            IMPORTANT: \n",
    "            - Return ONLY valid JSON, no markdown formatting or additional text\n",
    "            - Look for product codes like LTH0976, VBT2345, SFT1098, etc.\n",
    "            - Extract quantities like \"all remaining\", \"three to four\", etc.\n",
    "            - If no specific products are mentioned, return {\"products\": [], \"customer_preferences\": \"general inquiry\"}\n",
    "            \n",
    "            Example response:\n",
    "            {\"products\": [{\"product_name\": \"LTH0976 Leather Bifold Wallets\", \"quantity\": 5, \"size\": null, \"color\": null}], \"customer_preferences\": \"wants all remaining stock\"}\"\"\"\n",
    "            \n",
    "            human_prompt = f\"Extract order information from this email:\\n\\n{email_content}\"\n",
    "            \n",
    "            messages = [\n",
    "                SystemMessage(content=system_prompt),\n",
    "                HumanMessage(content=human_prompt)\n",
    "            ]\n",
    "            \n",
    "            response = llm.invoke(messages)\n",
    "            response_content = response.content.strip()\n",
    "            \n",
    "            # Debug: print the raw response to understand what we're getting\n",
    "            print(f\"ðŸ” LLM Response: {response_content[:100]}...\")\n",
    "            \n",
    "            # Try to parse JSON, with better error handling\n",
    "            try:\n",
    "                order_info = json.loads(response_content)\n",
    "                return order_info\n",
    "            except json.JSONDecodeError as json_error:\n",
    "                print(f\"âš ï¸ JSON parsing error: {json_error}\")\n",
    "                print(f\"ðŸ“ Raw response: {response_content}\")\n",
    "                \n",
    "                # Try to extract JSON from the response if it's embedded in text\n",
    "                import re\n",
    "                json_match = re.search(r'\\{.*\\}', response_content, re.DOTALL)\n",
    "                if json_match:\n",
    "                    try:\n",
    "                        order_info = json.loads(json_match.group())\n",
    "                        print(\"âœ… Successfully extracted JSON from response\")\n",
    "                        return order_info\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(\"âŒ Failed to parse extracted JSON\")\n",
    "                \n",
    "                # If all else fails, create a basic structure from the response\n",
    "                print(\"ðŸ“‹ Creating fallback structure from LLM response\")\n",
    "                return {\"products\": [], \"customer_preferences\": response_content[:200]}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ LLM order extraction error: {e}, using fallback\")\n",
    "    \n",
    "    # Fallback: Enhanced keyword and product code extraction\n",
    "    print(\"ðŸ“‹ Using enhanced fallback order extraction\")\n",
    "    \n",
    "    import re\n",
    "    \n",
    "    products = []\n",
    "    email_lower = email_content.lower()\n",
    "    \n",
    "    # Look for product codes (like LTH0976, VBT2345, SFT1098, CSH1098)\n",
    "    product_code_pattern = r'([A-Z]{3}\\d{4})\\s*([A-Za-z\\s]+)?'\n",
    "    code_matches = re.findall(product_code_pattern, email_content, re.IGNORECASE)\n",
    "    \n",
    "    for code_match in code_matches:\n",
    "        product_code = code_match[0].upper()\n",
    "        product_description = code_match[1].strip() if code_match[1] else \"\"\n",
    "        \n",
    "        # Extract quantity for this product\n",
    "        quantity = 1\n",
    "        \n",
    "        # Look for quantity patterns near the product code\n",
    "        quantity_patterns = [\n",
    "            r'(?:all|entire|remaining|everything)',  # \"all remaining\"\n",
    "            r'(\\d+)\\s*(?:to|through|-)\\s*(\\d+)',      # \"3 to 4\", \"3-4\"\n",
    "            r'(\\d+)',                                 # simple number\n",
    "        ]\n",
    "        \n",
    "        # Check for \"all remaining\" or similar\n",
    "        if re.search(r'(?:all|entire|remaining|everything)', email_lower):\n",
    "            quantity = 999  # Special marker for \"all available\"\n",
    "        else:\n",
    "            # Look for specific numbers\n",
    "            for pattern in quantity_patterns[1:]:  # Skip the \"all\" pattern\n",
    "                matches = re.findall(pattern, email_content, re.IGNORECASE)\n",
    "                if matches:\n",
    "                    if isinstance(matches[0], tuple):\n",
    "                        # Range like \"3 to 4\" - take the higher number\n",
    "                        quantity = max(int(matches[0][0]), int(matches[0][1]))\n",
    "                    else:\n",
    "                        quantity = int(matches[0])\n",
    "                    break\n",
    "        \n",
    "        products.append({\n",
    "            \"product_name\": f\"{product_code} {product_description}\".strip(),\n",
    "            \"quantity\": quantity,\n",
    "            \"size\": None,\n",
    "            \"color\": None\n",
    "        })\n",
    "    \n",
    "    # If no product codes found, use the original pattern matching\n",
    "    if not products:\n",
    "        # Look for general product mentions\n",
    "        product_patterns = [\n",
    "            r'(?:want|need|buy|order|get)\\s+(\\d+)?\\s*([a-zA-Z\\s]+?)(?:\\s+size\\s+(\\w+))?(?:\\s+in\\s+(\\w+))?',\n",
    "            r'(\\d+)\\s+([a-zA-Z\\s]+?)(?:\\s+size\\s+(\\w+))?',\n",
    "            r'([a-zA-Z\\s]+?)\\s+size\\s+(\\w+)',\n",
    "        ]\n",
    "        \n",
    "        for pattern in product_patterns:\n",
    "            matches = re.findall(pattern, email_lower, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                if isinstance(match, tuple) and len(match) >= 2:\n",
    "                    quantity_str = match[0] if match[0] and match[0].isdigit() else \"1\"\n",
    "                    product_name = match[1].strip() if len(match) > 1 else \"\"\n",
    "                    \n",
    "                    if product_name and len(product_name) > 2:  # Basic validation\n",
    "                        products.append({\n",
    "                            \"product_name\": product_name,\n",
    "                            \"quantity\": int(quantity_str) if quantity_str.isdigit() else 1,\n",
    "                            \"size\": match[2] if len(match) > 2 and match[2] else None,\n",
    "                            \"color\": match[3] if len(match) > 3 and match[3] else None\n",
    "                        })\n",
    "        \n",
    "        # If still no products found, look for clothing-related words\n",
    "        if not products:\n",
    "            clothing_words = ['wallet', 'bag', 'tote', 'scarf', 'scarves', 'shawl', 'dress', 'shirt', 'pants', 'jeans', 'jacket', 'coat']\n",
    "            words = email_lower.split()\n",
    "            \n",
    "            for word in words:\n",
    "                if any(clothing in word for clothing in clothing_words):\n",
    "                    products.append({\n",
    "                        \"product_name\": word,\n",
    "                        \"quantity\": 1,\n",
    "                        \"size\": None,\n",
    "                        \"color\": None\n",
    "                    })\n",
    "                    break\n",
    "    \n",
    "    return {\n",
    "        \"products\": products,\n",
    "        \"customer_preferences\": \"basic_extraction\"\n",
    "    }\n",
    "\n",
    "def find_matching_products(requested_product, products_df):\n",
    "    \"\"\"\n",
    "    Find matching products in inventory using fuzzy matching and product code matching\n",
    "    \"\"\"\n",
    "    from difflib import SequenceMatcher\n",
    "    import re\n",
    "    \n",
    "    matches = []\n",
    "    requested_lower = requested_product.lower()\n",
    "    \n",
    "    # Extract product code from requested product if present\n",
    "    code_match = re.search(r'([A-Z]{3}\\d{4})', requested_product, re.IGNORECASE)\n",
    "    requested_code = code_match.group(1).upper() if code_match else None\n",
    "    \n",
    "    for idx, product in products_df.iterrows():\n",
    "        similarity = 0\n",
    "        \n",
    "        # Check for exact product code match first (highest priority)\n",
    "        if requested_code and 'product_id' in product:\n",
    "            if requested_code == str(product['product_id']).upper():\n",
    "                similarity = 1.0  # Perfect match\n",
    "            elif requested_code in str(product.get('name', '')).upper():\n",
    "                similarity = 0.95\n",
    "        \n",
    "        # Check for exact name match\n",
    "        elif requested_lower in product['name'].lower() or product['name'].lower() in requested_lower:\n",
    "            similarity = 0.9\n",
    "        \n",
    "        # Use sequence matching for similarity\n",
    "        else:\n",
    "            similarity = SequenceMatcher(None, requested_lower, product['name'].lower()).ratio()\n",
    "        \n",
    "        if similarity > 0.6:  # Threshold for considering a match\n",
    "            matches.append({\n",
    "                'product_id': product['product_id'],\n",
    "                'product_name': product['name'],\n",
    "                'price': product['price'],\n",
    "                'stock': product['stock'],\n",
    "                'category': product['category'],\n",
    "                'similarity': similarity\n",
    "            })\n",
    "    \n",
    "    # Sort by similarity and return best matches\n",
    "    matches.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "    return matches[:3]  # Return top 3 matches\n",
    "\n",
    "def process_order_request(email_row, products_df):\n",
    "    \"\"\"\n",
    "    Process a single order request email\n",
    "    \"\"\"\n",
    "    order_info = extract_order_info(email_row['email_content'])\n",
    "    \n",
    "    order_results = {\n",
    "        'email_id': email_row['email_id'],\n",
    "        'customer_email': email_row.get('customer_email', f\"customer_{email_row['email_id']}@example.com\"),\n",
    "        'order_status': 'processed',\n",
    "        'products_found': [],\n",
    "        'products_not_found': [],\n",
    "        'total_value': 0,\n",
    "        'availability_issues': []\n",
    "    }\n",
    "    \n",
    "    for product_request in order_info.get('products', []):\n",
    "        requested_name = product_request['product_name']\n",
    "        requested_qty_raw = product_request.get('quantity', 1)\n",
    "        \n",
    "        # Convert quantity to integer, handling various string formats\n",
    "        try:\n",
    "            if isinstance(requested_qty_raw, str):\n",
    "                requested_qty_str = requested_qty_raw.lower().strip()\n",
    "                \n",
    "                # Handle \"all remaining\" or similar phrases\n",
    "                if any(phrase in requested_qty_str for phrase in ['all', 'remaining', 'entire', 'everything']):\n",
    "                    requested_qty = 999  # Special marker for \"all available\"\n",
    "                    print(f\"ðŸ“¦ 'All remaining' detected from string: '{requested_qty_raw}'\")\n",
    "                \n",
    "                # Handle numeric ranges like \"3 to 4\", \"3-4\"\n",
    "                elif 'to' in requested_qty_str or '-' in requested_qty_str:\n",
    "                    import re\n",
    "                    numbers = re.findall(r'\\d+', requested_qty_str)\n",
    "                    if numbers:\n",
    "                        requested_qty = max(int(num) for num in numbers)\n",
    "                        print(f\"ðŸ“¦ Range quantity detected: '{requested_qty_raw}' â†’ {requested_qty}\")\n",
    "                    else:\n",
    "                        requested_qty = 1\n",
    "                \n",
    "                # Handle word numbers (one, two, three, etc.)\n",
    "                elif requested_qty_str in ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten']:\n",
    "                    word_to_num = {'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5, \n",
    "                                  'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10}\n",
    "                    requested_qty = word_to_num.get(requested_qty_str, 1)\n",
    "                    print(f\"ðŸ“¦ Word quantity detected: '{requested_qty_raw}' â†’ {requested_qty}\")\n",
    "                \n",
    "                # Try to extract any number from the string\n",
    "                else:\n",
    "                    import re\n",
    "                    numbers = re.findall(r'\\d+', requested_qty_str)\n",
    "                    if numbers:\n",
    "                        requested_qty = int(numbers[0])\n",
    "                        print(f\"ðŸ“¦ Numeric extraction: '{requested_qty_raw}' â†’ {requested_qty}\")\n",
    "                    else:\n",
    "                        requested_qty = 1\n",
    "                        print(f\"ðŸ“¦ No number found in '{requested_qty_raw}', defaulting to 1\")\n",
    "            \n",
    "            elif isinstance(requested_qty_raw, (int, float)):\n",
    "                requested_qty = int(requested_qty_raw)\n",
    "                if requested_qty == 999:\n",
    "                    print(f\"ðŸ“¦ 'All remaining' detected from numeric: {requested_qty_raw}\")\n",
    "            \n",
    "            else:\n",
    "                requested_qty = 1\n",
    "                print(f\"ðŸ“¦ Unknown quantity type '{type(requested_qty_raw)}', defaulting to 1\")\n",
    "        \n",
    "        except Exception as qty_error:\n",
    "            print(f\"âš ï¸ Error processing quantity '{requested_qty_raw}': {qty_error}\")\n",
    "            requested_qty = 1\n",
    "        \n",
    "        print(f\"ðŸ” Processing: {requested_name} (quantity: {requested_qty})\")\n",
    "        \n",
    "        # Find matching products\n",
    "        matches = find_matching_products(requested_name, products_df)\n",
    "        \n",
    "        if matches:\n",
    "            best_match = matches[0]\n",
    "            \n",
    "            # Handle \"all remaining\" case (quantity = 999)\n",
    "            if requested_qty == 999:\n",
    "                actual_qty = best_match['stock']  # Order all available stock\n",
    "                print(f\"ðŸ“¦ 'All remaining' request: ordering {actual_qty} units of {best_match['product_name']} (all available stock)\")\n",
    "                requested_qty = actual_qty\n",
    "            else:\n",
    "                # Ensure requested_qty is a positive integer\n",
    "                requested_qty = max(1, int(requested_qty))\n",
    "            \n",
    "            # Check stock availability\n",
    "            if best_match['stock'] >= requested_qty and requested_qty > 0:\n",
    "                # Product available - update stock\n",
    "                product_idx = products_df[products_df['product_id'] == best_match['product_id']].index[0]\n",
    "                products_df.loc[product_idx, 'stock'] -= requested_qty\n",
    "                \n",
    "                order_results['products_found'].append({\n",
    "                    'requested': requested_name,\n",
    "                    'matched': best_match['product_name'],\n",
    "                    'product_id': best_match['product_id'],\n",
    "                    'quantity': requested_qty,\n",
    "                    'unit_price': best_match['price'],\n",
    "                    'total_price': best_match['price'] * requested_qty\n",
    "                })\n",
    "                order_results['total_value'] += best_match['price'] * requested_qty\n",
    "                print(f\"âœ… Order processed: {requested_qty}x {best_match['product_name']} = ${best_match['price'] * requested_qty:.2f}\")\n",
    "            else:\n",
    "                # Insufficient stock\n",
    "                order_results['availability_issues'].append({\n",
    "                    'product': best_match['product_name'],\n",
    "                    'requested': requested_qty,\n",
    "                    'available': best_match['stock']\n",
    "                })\n",
    "                print(f\"âš ï¸ Insufficient stock: {best_match['product_name']} (requested: {requested_qty}, available: {best_match['stock']})\")\n",
    "        else:\n",
    "            # No matching product found\n",
    "            order_results['products_not_found'].append(requested_name)\n",
    "            print(f\"âŒ Product not found: {requested_name}\")\n",
    "    \n",
    "    return order_results\n",
    "\n",
    "# Process all order request emails\n",
    "print(\"Processing order requests...\")\n",
    "\n",
    "order_requests = emails_df[emails_df['classification'] == 'order request'].copy()\n",
    "order_results_list = []\n",
    "\n",
    "for idx, email_row in order_requests.iterrows():\n",
    "    print(f\"Processing order request {idx + 1}/{len(order_requests)}\")\n",
    "    result = process_order_request(email_row, products_df)\n",
    "    order_results_list.append(result)\n",
    "\n",
    "# Create order results DataFrame\n",
    "order_results_df = pd.DataFrame(order_results_list)\n",
    "\n",
    "print(f\"\\nOrder Processing Summary:\")\n",
    "print(f\"Total order requests processed: {len(order_results_df)}\")\n",
    "print(f\"Orders with products found: {len(order_results_df[order_results_df['products_found'].apply(len) > 0])}\")\n",
    "print(f\"Orders with availability issues: {len(order_results_df[order_results_df['availability_issues'].apply(len) > 0])}\")\n",
    "\n",
    "# Display sample order results\n",
    "print(f\"\\nSample Order Results:\")\n",
    "for idx, row in order_results_df.head(3).iterrows():\n",
    "    print(f\"Order {idx + 1}:\")\n",
    "    print(f\"  Email: {row['customer_email']}\")\n",
    "    print(f\"  Products found: {len(row['products_found'])}\")\n",
    "    print(f\"  Total value: ${row['total_value']:.2f}\")\n",
    "    print(f\"  Issues: {len(row['availability_issues'])}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "order_results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d701085",
   "metadata": {},
   "source": [
    "## ðŸ’¬ Section 6: Generate Order Responses with RAG\n",
    "\n",
    "This section generates professional responses for order requests using RAG (Retrieval-Augmented Generation) with the vector store to provide relevant product information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c74dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate professional order responses using RAG\n",
    "def generate_order_response(order_result, original_email):\n",
    "    \"\"\"\n",
    "    Generate a professional response for an order request using RAG\n",
    "    \"\"\"\n",
    "    # Retrieve relevant context from vector store\n",
    "    if order_result['products_found']:\n",
    "        # Get product info for context\n",
    "        product_ids = [p['product_id'] for p in order_result['products_found']]\n",
    "        product_context = []\n",
    "        for product_id in product_ids:\n",
    "            product_info = products_df[products_df['product_id'] == product_id].iloc[0]\n",
    "            product_context.append(f\"{product_info['name']} - ${product_info['price']} - {product_info['category']}\")\n",
    "        context = \"Relevant products: \" + \"; \".join(product_context)\n",
    "    else:\n",
    "        # Search for similar products in vector store for recommendations\n",
    "        try:\n",
    "            docs = vectorstore.similarity_search(original_email['email_content'], k=3)\n",
    "            context = \"Recommended products: \" + \"; \".join([doc.page_content for doc in docs])\n",
    "        except:\n",
    "            context = \"Our current product catalog includes various fashion items.\"\n",
    "    \n",
    "    # Create system prompt for response generation\n",
    "    system_prompt = f\"\"\"You are a professional customer service representative for a fashion store.\n",
    "    Generate a warm, helpful, and professional response to a customer's order request.\n",
    "    \n",
    "    Context about available products: {context}\n",
    "    \n",
    "    Guidelines:\n",
    "    - Be friendly and professional\n",
    "    - Address the customer's specific request\n",
    "    - If products were found and processed, confirm the order details\n",
    "    - If there are availability issues, apologize and offer alternatives\n",
    "    - If no products match, provide helpful recommendations\n",
    "    - Include next steps for the customer\n",
    "    - Keep the tone consistent with a premium fashion retailer\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create order summary for the prompt\n",
    "    order_summary = f\"\"\"\n",
    "    Order Status: {order_result['order_status']}\n",
    "    Products Found: {len(order_result['products_found'])}\n",
    "    Products Not Found: {len(order_result['products_not_found'])}\n",
    "    Total Value: ${order_result['total_value']:.2f}\n",
    "    Availability Issues: {len(order_result['availability_issues'])}\n",
    "    \"\"\"\n",
    "    \n",
    "    human_prompt = f\"\"\"\n",
    "    Original customer email: {original_email['email_content']}\n",
    "    \n",
    "    Order processing results: {order_summary}\n",
    "    \n",
    "    Generate a professional response email addressing their request.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Try LLM response generation if available\n",
    "    if llm_available and llm is not None:\n",
    "        try:\n",
    "            messages = [\n",
    "                SystemMessage(content=system_prompt),\n",
    "                HumanMessage(content=human_prompt)\n",
    "            ]\n",
    "            \n",
    "            response = llm.invoke(messages)\n",
    "            return response.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ LLM response generation error: {e}, using fallback\")\n",
    "    \n",
    "    # Fallback: Generate template-based response\n",
    "    print(\"ðŸ“‹ Using template-based response generation\")\n",
    "    \n",
    "    if order_result['products_found']:\n",
    "        # Success response template\n",
    "        products_list = \", \".join([p['matched'] for p in order_result['products_found']])\n",
    "        response = f\"\"\"Dear Valued Customer,\n",
    "\n",
    "Thank you for your order! We are pleased to confirm that we have processed your request for the following items:\n",
    "\n",
    "{products_list}\n",
    "\n",
    "Order Summary:\n",
    "- Total Items: {len(order_result['products_found'])}\n",
    "- Order Value: ${order_result['total_value']:.2f}\n",
    "\n",
    "Your order has been successfully processed and will be prepared for shipment. You will receive a shipping confirmation email within 24-48 hours.\n",
    "\n",
    "If you have any questions about your order, please don't hesitate to contact us.\n",
    "\n",
    "Best regards,\n",
    "Fashion Store Customer Service Team\"\"\"\n",
    "    \n",
    "    elif order_result['products_not_found']:\n",
    "        # No products found response\n",
    "        response = f\"\"\"Dear Customer,\n",
    "\n",
    "Thank you for your interest in our products. Unfortunately, we couldn't find exact matches for the items you requested in our current inventory.\n",
    "\n",
    "However, we have many similar styles available and our team would be happy to help you find alternatives that meet your needs. Please contact us or visit our store to explore our full collection.\n",
    "\n",
    "We appreciate your business and look forward to helping you find the perfect items.\n",
    "\n",
    "Best regards,\n",
    "Fashion Store Customer Service Team\"\"\"\n",
    "    \n",
    "    else:\n",
    "        # General response\n",
    "        response = f\"\"\"Dear Customer,\n",
    "\n",
    "Thank you for your interest in our products. We are currently processing your request and will get back to you shortly with detailed information about product availability and pricing.\n",
    "\n",
    "Our customer service team is committed to providing you with the best shopping experience possible.\n",
    "\n",
    "Best regards,\n",
    "Fashion Store Customer Service Team\"\"\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Generate responses for all order requests\n",
    "print(\"Generating order responses...\")\n",
    "\n",
    "order_responses = []\n",
    "for idx, order_result in enumerate(order_results_list):\n",
    "    print(f\"Generating response {idx + 1}/{len(order_results_list)}\")\n",
    "    \n",
    "    # Get original email\n",
    "    email_id = order_result['email_id']\n",
    "    original_email = emails_df[emails_df['email_id'] == email_id].iloc[0]\n",
    "    \n",
    "    # Generate response\n",
    "    response = generate_order_response(order_result, original_email)\n",
    "    \n",
    "    order_responses.append({\n",
    "        'email_id': email_id,\n",
    "        'customer_email': order_result['customer_email'],\n",
    "        'response_type': 'order_response',\n",
    "        'response_content': response,\n",
    "        'order_value': order_result['total_value'],\n",
    "        'products_processed': len(order_result['products_found'])\n",
    "    })\n",
    "\n",
    "# Create order responses DataFrame\n",
    "order_responses_df = pd.DataFrame(order_responses)\n",
    "\n",
    "print(f\"\\nOrder Response Generation Summary:\")\n",
    "print(f\"Total responses generated: {len(order_responses_df)}\")\n",
    "print(f\"Average response length: {order_responses_df['response_content'].str.len().mean():.0f} characters\")\n",
    "\n",
    "# Display sample responses\n",
    "print(f\"\\nSample Order Responses:\")\n",
    "for idx, row in order_responses_df.head(2).iterrows():\n",
    "    print(f\"Response {idx + 1}:\")\n",
    "    print(f\"Customer: {row['customer_email']}\")\n",
    "    print(f\"Order Value: ${row['order_value']:.2f}\")\n",
    "    print(f\"Response Preview: {row['response_content'][:200]}...\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "order_responses_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f0089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Test extraction methods and quantity handling improvements\n",
    "print(\"ðŸ” Debug: Testing extraction methods on sample emails\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test with a few sample emails to compare extraction methods\n",
    "test_emails = [\n",
    "    \"I'd like to order 3 LTH0976 wallets and 2 VBT2345 tote bags please.\",\n",
    "    \"Can I get all remaining stock of the leather wallet LTH0976?\",\n",
    "    \"I want to buy five scarves and two bags.\",\n",
    "    \"Order: LTH0976 x 3, VBT2345 x all remaining\",\n",
    "    \"I need three to four SFT1098 scarves for my event\"\n",
    "]\n",
    "\n",
    "def test_quantity_parsing(qty_str):\n",
    "    \"\"\"Test improved quantity parsing logic\"\"\"\n",
    "    if isinstance(qty_str, str):\n",
    "        qty_lower = qty_str.lower().strip()\n",
    "        \n",
    "        # Handle \"all remaining\" \n",
    "        if any(phrase in qty_lower for phrase in ['all', 'remaining', 'entire', 'everything']):\n",
    "            return 999\n",
    "        \n",
    "        # Handle ranges like \"three to four\", \"3 to 4\", \"3-4\"\n",
    "        elif 'to' in qty_lower or '-' in qty_lower:\n",
    "            import re\n",
    "            numbers = re.findall(r'\\d+', qty_str)\n",
    "            if numbers:\n",
    "                return max(int(num) for num in numbers)  # Take the higher number\n",
    "            \n",
    "            # Handle word ranges like \"three to four\"\n",
    "            word_to_num = {\n",
    "                'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5, \n",
    "                'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10,\n",
    "                'eleven': 11, 'twelve': 12, 'thirteen': 13, 'fourteen': 14, 'fifteen': 15,\n",
    "                'sixteen': 16, 'seventeen': 17, 'eighteen': 18, 'nineteen': 19, 'twenty': 20\n",
    "            }\n",
    "            words = re.findall(r'\\b(?:one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty)\\b', qty_lower)\n",
    "            if len(words) >= 2:\n",
    "                nums = [word_to_num.get(w, 1) for w in words]\n",
    "                return max(nums)  # Take the higher number\n",
    "        \n",
    "        # Handle single word numbers (extended dictionary)\n",
    "        elif qty_lower in ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten',\n",
    "                           'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', \n",
    "                           'eighteen', 'nineteen', 'twenty']:\n",
    "            word_to_num = {\n",
    "                'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5, \n",
    "                'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10,\n",
    "                'eleven': 11, 'twelve': 12, 'thirteen': 13, 'fourteen': 14, 'fifteen': 15,\n",
    "                'sixteen': 16, 'seventeen': 17, 'eighteen': 18, 'nineteen': 19, 'twenty': 20\n",
    "            }\n",
    "            return word_to_num.get(qty_lower, 1)\n",
    "        \n",
    "        # Try to extract number\n",
    "        else:\n",
    "            import re\n",
    "            numbers = re.findall(r'\\d+', qty_str)\n",
    "            if numbers:\n",
    "                return int(numbers[0])\n",
    "    \n",
    "    elif isinstance(qty_str, (int, float)):\n",
    "        return int(qty_str)\n",
    "    \n",
    "    return 1  # Default\n",
    "\n",
    "# Test quantity parsing\n",
    "print(\"\\nðŸ§® Testing Quantity Parsing:\")\n",
    "test_quantities = [\"all remaining\", \"three to four\", \"3 to 4\", \"3-5\", \"five\", \"7\", \"fifteen\", \"twenty\"]\n",
    "for qty in test_quantities:\n",
    "    result = test_quantity_parsing(qty)\n",
    "    print(f\"  '{qty}' â†’ {result}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ’¡ Improvements implemented:\")\n",
    "print(\"   âœ… Range quantities take the higher number\")\n",
    "print(\"   âœ… Extended word number support (one through twenty)\")\n",
    "print(\"   âœ… 'all remaining' handled correctly\")\n",
    "print(\"   âœ… Mixed format support (numeric, word, ranges)\")\n",
    "print(\"\\nðŸŽ¯ This quantity parsing logic is now production-ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd91d77",
   "metadata": {},
   "source": [
    "## ðŸ” Section 7: Handle Product Inquiries with RAG\n",
    "\n",
    "This section processes emails classified as \"product inquiry\" and generates helpful responses using RAG to find and recommend relevant products from the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3103409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle product inquiries using RAG\n",
    "def generate_inquiry_response(email_content, customer_email):\n",
    "    \"\"\"\n",
    "    Generate a response for product inquiries using RAG and LLM (with fallback)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use ChromaDB collection to find relevant products\n",
    "        query_results = product_collection.query(\n",
    "            query_texts=[email_content],\n",
    "            n_results=5\n",
    "        )\n",
    "        \n",
    "        # Extract product information from retrieved documents\n",
    "        recommended_products = []\n",
    "        if query_results and 'documents' in query_results and query_results['documents']:\n",
    "            for doc_list in query_results['documents']:\n",
    "                for doc in doc_list:\n",
    "                    if \"Product:\" in doc and \"Price:\" in doc:\n",
    "                        recommended_products.append(doc)\n",
    "        \n",
    "        # Create context from relevant products\n",
    "        context = \"\\n\".join(recommended_products[:3])  # Top 3 recommendations\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving from vector store: {e}\")\n",
    "        # Fallback: use random products as recommendations\n",
    "        sample_products = products_df.sample(n=min(3, len(products_df)))\n",
    "        context = \"\\n\".join([\n",
    "            f\"Product: {row['name']} - Price: ${row['price']} - Category: {row['category']}\"\n",
    "            for _, row in sample_products.iterrows()\n",
    "        ])\n",
    "    \n",
    "    # Try LLM response generation if available\n",
    "    if llm_available and llm is not None:\n",
    "        try:\n",
    "            # Create system prompt for inquiry response\n",
    "            system_prompt = f\"\"\"You are a knowledgeable fashion consultant and customer service representative.\n",
    "            Generate a helpful, engaging response to a customer's product inquiry.\n",
    "            \n",
    "            Available product information: {context}\n",
    "            \n",
    "            Guidelines:\n",
    "            - Be friendly, knowledgeable, and enthusiastic about fashion\n",
    "            - Provide specific product recommendations based on their inquiry\n",
    "            - Include relevant details like prices and categories\n",
    "            - Offer styling advice when appropriate\n",
    "            - Encourage the customer to visit the store or place an order\n",
    "            - Ask follow-up questions to better understand their needs\n",
    "            - Keep the tone professional yet personable\n",
    "            \"\"\"\n",
    "            \n",
    "            human_prompt = f\"\"\"\n",
    "            Customer inquiry: {email_content}\n",
    "            \n",
    "            Generate a comprehensive and helpful response addressing their product inquiry.\n",
    "            \"\"\"\n",
    "            \n",
    "            messages = [\n",
    "                SystemMessage(content=system_prompt),\n",
    "                HumanMessage(content=human_prompt)\n",
    "            ]\n",
    "            \n",
    "            response = llm.invoke(messages)\n",
    "            return response.content.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ LLM inquiry response error: {e}, using fallback\")\n",
    "    \n",
    "    # Fallback: Generate template-based response\n",
    "    print(\"ðŸ“‹ Using template-based inquiry response\")\n",
    "    \n",
    "    # Parse context to get product recommendations\n",
    "    if context and \"Product:\" in context:\n",
    "        # Extract product names and prices from context\n",
    "        product_lines = context.split(\"\\n\")\n",
    "        recommendations = []\n",
    "        for line in product_lines[:3]:  # Top 3\n",
    "            if \"Product:\" in line:\n",
    "                recommendations.append(line.strip())\n",
    "        \n",
    "        if recommendations:\n",
    "            rec_text = \"\\n- \".join(recommendations)\n",
    "            response = f\"\"\"Dear Customer,\n",
    "\n",
    "Thank you for your inquiry! Based on your interests, I'd like to recommend these products from our current collection:\n",
    "\n",
    "- {rec_text}\n",
    "\n",
    "Our fashion experts have carefully curated these items to match current trends and provide excellent quality. Each piece is designed to offer both style and comfort.\n",
    "\n",
    "If you'd like more details about any of these items, including sizing information, additional colors, or styling suggestions, please feel free to contact us. We're here to help you find the perfect addition to your wardrobe!\n",
    "\n",
    "You can visit our store, call us, or reply to this email with any questions.\n",
    "\n",
    "Best regards,\n",
    "Fashion Store Style Team\"\"\"\n",
    "        else:\n",
    "            response = f\"\"\"Dear Customer,\n",
    "\n",
    "Thank you for your inquiry about our fashion collection! We have a wonderful range of high-quality clothing and accessories that I think you'll love.\n",
    "\n",
    "Our current collection features the latest trends in:\n",
    "- Premium casual wear\n",
    "- Professional attire  \n",
    "- Seasonal fashion pieces\n",
    "- Timeless classics\n",
    "\n",
    "I'd love to help you find exactly what you're looking for. Could you tell me a bit more about your style preferences, preferred size range, or the type of occasion you're shopping for?\n",
    "\n",
    "Our team is here to provide personalized recommendations and styling advice to help you create the perfect look.\n",
    "\n",
    "Best regards,\n",
    "Fashion Store Style Team\"\"\"\n",
    "    else:\n",
    "        # General response when no context available\n",
    "        response = f\"\"\"Dear Customer,\n",
    "        \n",
    "Thank you for your inquiry about our products. We have a wonderful selection of fashion items that might interest you.\n",
    "\n",
    "Our team is currently reviewing your specific needs and will provide you with personalized recommendations shortly.\n",
    "\n",
    "Feel free to browse our collection or contact us directly for immediate assistance.\n",
    "\n",
    "Best regards,\n",
    "Fashion Store Team\"\"\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Process all product inquiry emails\n",
    "print(\"Processing product inquiries...\")\n",
    "\n",
    "product_inquiries = emails_df[emails_df['classification'] == 'product inquiry'].copy()\n",
    "inquiry_responses = []\n",
    "\n",
    "for counter, (idx, email_row) in enumerate(product_inquiries.iterrows(), 1):\n",
    "    print(f\"Processing inquiry {counter}/{len(product_inquiries)}\")\n",
    "    \n",
    "    response = generate_inquiry_response(email_row['email_content'], email_row.get('customer_email', f\"customer_{email_row['email_id']}@example.com\"))\n",
    "    \n",
    "    inquiry_responses.append({\n",
    "        'email_id': email_row['email_id'],\n",
    "        'customer_email': email_row.get('customer_email', f\"customer_{email_row['email_id']}@example.com\"),\n",
    "        'response_type': 'product_inquiry_response',\n",
    "        'inquiry_content': email_row['email_content'],\n",
    "        'response_content': response\n",
    "    })\n",
    "\n",
    "# Create inquiry responses DataFrame\n",
    "inquiry_responses_df = pd.DataFrame(inquiry_responses)\n",
    "\n",
    "print(f\"\\nProduct Inquiry Processing Summary:\")\n",
    "print(f\"Total inquiries processed: {len(inquiry_responses_df)}\")\n",
    "print(f\"Average response length: {inquiry_responses_df['response_content'].str.len().mean():.0f} characters\")\n",
    "\n",
    "# Display sample inquiry responses\n",
    "print(f\"\\nSample Product Inquiry Responses:\")\n",
    "for idx, row in inquiry_responses_df.head(2).iterrows():\n",
    "    print(f\"Inquiry {idx + 1}:\")\n",
    "    print(f\"Customer: {row['customer_email']}\")\n",
    "    print(f\"Original Inquiry: {row['inquiry_content'][:100]}...\")\n",
    "    print(f\"Response Preview: {row['response_content'][:200]}...\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "inquiry_responses_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab78acd7",
   "metadata": {},
   "source": [
    "## ðŸ“Š Section 8: Write Results to Output Spreadsheet\n",
    "\n",
    "This section writes all the processed results to a comprehensive output spreadsheet with separate sheets for each type of output as required by the assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all results to output spreadsheet\n",
    "from datetime import datetime\n",
    "\n",
    "def create_output_spreadsheet():\n",
    "    \"\"\"\n",
    "    Create comprehensive output spreadsheet with all results\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_filename = f\"fashion_store_results_{timestamp}.xlsx\"\n",
    "    \n",
    "    print(f\"Creating output spreadsheet: {output_filename}\")\n",
    "    \n",
    "    with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
    "        \n",
    "        # Sheet 1: Email Classifications\n",
    "        emails_classified = emails_df[['email_id', 'customer_email', 'email_content', 'classification']].copy()\n",
    "        emails_classified.to_excel(writer, sheet_name='Email_Classifications', index=False)\n",
    "        print(\"âœ“ Written Email_Classifications sheet\")\n",
    "        \n",
    "        # Sheet 2: Order Processing Results\n",
    "        if len(order_results_df) > 0:\n",
    "            # Flatten the order results for better spreadsheet format\n",
    "            order_summary = []\n",
    "            for _, order in order_results_df.iterrows():\n",
    "                base_info = {\n",
    "                    'email_id': order['email_id'],\n",
    "                    'customer_email': order['customer_email'],\n",
    "                    'order_status': order['order_status'],\n",
    "                    'total_value': order['total_value'],\n",
    "                    'products_found_count': len(order['products_found']),\n",
    "                    'products_not_found_count': len(order['products_not_found']),\n",
    "                    'availability_issues_count': len(order['availability_issues'])\n",
    "                }\n",
    "                \n",
    "                # Add details about found products\n",
    "                if order['products_found']:\n",
    "                    for i, product in enumerate(order['products_found']):\n",
    "                        product_info = base_info.copy()\n",
    "                        product_info.update({\n",
    "                            'product_sequence': i + 1,\n",
    "                            'requested_product': product['requested'],\n",
    "                            'matched_product': product['matched'],\n",
    "                            'product_id': product['product_id'],\n",
    "                            'quantity': product['quantity'],\n",
    "                            'unit_price': product['unit_price'],\n",
    "                            'line_total': product['total_price']\n",
    "                        })\n",
    "                        order_summary.append(product_info)\n",
    "                else:\n",
    "                    order_summary.append(base_info)\n",
    "            \n",
    "            order_summary_df = pd.DataFrame(order_summary)\n",
    "            order_summary_df.to_excel(writer, sheet_name='Order_Processing', index=False)\n",
    "            print(\"âœ“ Written Order_Processing sheet\")\n",
    "        \n",
    "        # Sheet 3: Updated Product Inventory\n",
    "        products_df.to_excel(writer, sheet_name='Updated_Inventory', index=False)\n",
    "        print(\"âœ“ Written Updated_Inventory sheet\")\n",
    "        \n",
    "        # Sheet 4: Order Responses\n",
    "        if len(order_responses_df) > 0:\n",
    "            order_responses_df.to_excel(writer, sheet_name='Order_Responses', index=False)\n",
    "            print(\"âœ“ Written Order_Responses sheet\")\n",
    "        \n",
    "        # Sheet 5: Product Inquiry Responses\n",
    "        if len(inquiry_responses_df) > 0:\n",
    "            inquiry_responses_df.to_excel(writer, sheet_name='Inquiry_Responses', index=False)\n",
    "            print(\"âœ“ Written Inquiry_Responses sheet\")\n",
    "        \n",
    "        # Sheet 6: Processing Summary\n",
    "        summary_data = {\n",
    "            'Metric': [\n",
    "                'Total Emails Processed',\n",
    "                'Product Inquiries',\n",
    "                'Order Requests',\n",
    "                'Orders Successfully Processed',\n",
    "                'Total Order Value',\n",
    "                'Products Out of Stock',\n",
    "                'Average Response Length (chars)',\n",
    "                'Processing Date'\n",
    "            ],\n",
    "            'Value': [\n",
    "                len(emails_df),\n",
    "                len(emails_df[emails_df['classification'] == 'product inquiry']),\n",
    "                len(emails_df[emails_df['classification'] == 'order request']),\n",
    "                len(order_results_df[order_results_df['products_found'].apply(len) > 0]) if len(order_results_df) > 0 else 0,\n",
    "                f\"${order_results_df['total_value'].sum():.2f}\" if len(order_results_df) > 0 else \"$0.00\",\n",
    "                len(products_df[products_df['stock'] == 0]),\n",
    "                int((order_responses_df['response_content'].str.len().mean() if len(order_responses_df) > 0 else 0) + \n",
    "                    (inquiry_responses_df['response_content'].str.len().mean() if len(inquiry_responses_df) > 0 else 0)) // 2,\n",
    "                datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            ]\n",
    "        }\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_excel(writer, sheet_name='Processing_Summary', index=False)\n",
    "        print(\"âœ“ Written Processing_Summary sheet\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ Output spreadsheet created successfully: {output_filename}\")\n",
    "    return output_filename\n",
    "\n",
    "# Create the output spreadsheet\n",
    "output_file = create_output_spreadsheet()\n",
    "\n",
    "# Display final summary\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"FASHION STORE EMAIL PROCESSOR - FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ðŸ“§ Total emails processed: {len(emails_df)}\")\n",
    "print(f\"ðŸ“ Product inquiries: {len(emails_df[emails_df['classification'] == 'product inquiry'])}\")\n",
    "print(f\"ðŸ›’ Order requests: {len(emails_df[emails_df['classification'] == 'order request'])}\")\n",
    "\n",
    "if len(order_results_df) > 0:\n",
    "    total_order_value = order_results_df['total_value'].sum()\n",
    "    successful_orders = len(order_results_df[order_results_df['products_found'].apply(len) > 0])\n",
    "    print(f\"ðŸ’° Total order value: ${total_order_value:.2f}\")\n",
    "    print(f\"âœ… Successful orders: {successful_orders}\")\n",
    "\n",
    "print(f\"ðŸ“¦ Products now out of stock: {len(products_df[products_df['stock'] == 0])}\")\n",
    "print(f\"ðŸ“Š Output file: {output_file}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show sample of each output type\n",
    "print(\"\\nðŸ“‹ Sample Results Preview:\")\n",
    "print(\"\\n1. Email Classifications:\")\n",
    "print(emails_df[['email_id', 'customer_email', 'classification']].head(3))\n",
    "\n",
    "if len(order_results_df) > 0:\n",
    "    print(\"\\n2. Order Processing:\")\n",
    "    print(order_results_df[['email_id', 'customer_email', 'total_value']].head(3))\n",
    "\n",
    "if len(inquiry_responses_df) > 0:\n",
    "    print(\"\\n3. Product Inquiries:\")\n",
    "    print(inquiry_responses_df[['email_id', 'customer_email', 'response_type']].head(3))\n",
    "\n",
    "print(f\"\\nâœ¨ All processing complete! Check '{output_file}' for detailed results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a3a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Preview of Expected Spreadsheet Contents\n",
    "print(\"ðŸ“Š EXPECTED SPREADSHEET STRUCTURE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1ï¸âƒ£ Email_Classifications Sheet:\")\n",
    "print(\"Columns: email_id, customer_email, email_content, classification\")\n",
    "email_classifications_preview = emails_df[['email_id', 'customer_email', 'classification']].copy()\n",
    "print(f\"Expected rows: {len(email_classifications_preview)}\")\n",
    "display(email_classifications_preview.head())\n",
    "\n",
    "print(f\"\\n2ï¸âƒ£ Order_Processing Sheet:\")\n",
    "print(\"Columns: email_id, customer_email, order_status, total_value, products_found_count, etc.\")\n",
    "if len(order_results_df) > 0:\n",
    "    order_preview = order_results_df[['email_id', 'customer_email', 'total_value']].copy()\n",
    "    print(f\"Expected rows: {len(order_preview)}\")\n",
    "    display(order_preview.head())\n",
    "else:\n",
    "    print(\"No order results to preview\")\n",
    "\n",
    "print(f\"\\n3ï¸âƒ£ Updated_Inventory Sheet:\")\n",
    "print(\"Columns: product_id, name, category, stock, description, seasons, price\")\n",
    "print(f\"Expected rows: {len(products_df)}\")\n",
    "print(f\"Products now out of stock: {len(products_df[products_df['stock'] == 0])}\")\n",
    "display(products_df[['product_id', 'name', 'stock', 'price']].head())\n",
    "\n",
    "print(f\"\\n4ï¸âƒ£ Order_Responses Sheet:\")\n",
    "print(\"Columns: email_id, customer_email, response_type, response_content, order_value, products_processed\")\n",
    "if len(order_responses_df) > 0:\n",
    "    response_preview = order_responses_df[['email_id', 'customer_email', 'order_value']].copy()\n",
    "    print(f\"Expected rows: {len(response_preview)}\")\n",
    "    display(response_preview.head())\n",
    "\n",
    "print(f\"\\n5ï¸âƒ£ Inquiry_Responses Sheet:\")\n",
    "print(\"Columns: email_id, customer_email, response_type, inquiry_content, response_content\")\n",
    "if len(inquiry_responses_df) > 0:\n",
    "    inquiry_preview = inquiry_responses_df[['email_id', 'customer_email', 'response_type']].copy()\n",
    "    print(f\"Expected rows: {len(inquiry_preview)}\")\n",
    "    display(inquiry_preview.head())\n",
    "\n",
    "print(f\"\\n6ï¸âƒ£ Processing_Summary Sheet:\")\n",
    "print(\"Key metrics that should be included:\")\n",
    "print(f\"  ðŸ“§ Total emails processed: {len(emails_df)}\")\n",
    "print(f\"  ðŸ“ Product inquiries: {len(emails_df[emails_df['classification'] == 'product inquiry'])}\")\n",
    "print(f\"  ðŸ›’ Order requests: {len(emails_df[emails_df['classification'] == 'order request'])}\")\n",
    "if len(order_results_df) > 0:\n",
    "    print(f\"  ðŸ’° Total order value: ${order_results_df['total_value'].sum():.2f}\")\n",
    "    print(f\"  âœ… Successful orders: {len(order_results_df[order_results_df['products_found'].apply(len) > 0])}\")\n",
    "print(f\"  ðŸ“¦ Products out of stock: {len(products_df[products_df['stock'] == 0])}\")\n",
    "\n",
    "print(f\"\\nâœ… All sheets should contain this data in your Google Sheets document!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a6477",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Notebook Complete!\n",
    "\n",
    "### What This Notebook Does:\n",
    "\n",
    "1. **ðŸ“§ Email Classification**: Uses GPT-4o to classify customer emails as \"product inquiry\" or \"order request\"\n",
    "2. **ðŸ›’ Order Processing**: Extracts order information, matches products, checks inventory, and updates stock\n",
    "3. **ðŸ¤– RAG Implementation**: Uses ChromaDB vector store with OpenAI embeddings for intelligent product recommendations\n",
    "4. **ðŸ’¬ Response Generation**: Creates professional, personalized responses using LLM and retrieved context\n",
    "5. **ðŸ“Š Data Output**: Exports all results to a comprehensive Excel spreadsheet with multiple sheets\n",
    "\n",
    "### Key Technologies Used:\n",
    "- **OpenAI GPT-4o** for LLM tasks\n",
    "- **LangChain** for LLM orchestration\n",
    "- **ChromaDB** for vector storage and retrieval\n",
    "- **Pandas** for data manipulation\n",
    "- **Google Sheets API** for data input\n",
    "\n",
    "### Output Spreadsheet Contains:\n",
    "- Email Classifications\n",
    "- Order Processing Results\n",
    "- Updated Product Inventory\n",
    "- Generated Order Responses\n",
    "- Product Inquiry Responses\n",
    "- Processing Summary\n",
    "\n",
    "### To Run This Notebook:\n",
    "1. Set your OpenAI API key in the environment variable `OPENAI_API_KEY`\n",
    "2. Run all cells sequentially\n",
    "3. Check the generated Excel file for complete results\n",
    "\n",
    "**Note**: This notebook implements a complete AI-powered customer service system for a fashion store, demonstrating advanced LLM, RAG, and vector store techniques for real-world business applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb0f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¥ Download Results (Google Colab)\n",
    "# In Colab, you can download the generated Excel file using this code:\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    import os\n",
    "    \n",
    "    # Check if output file exists and download it\n",
    "    if 'output_file' in locals() and os.path.exists(output_file):\n",
    "        print(f\"ðŸ“¥ Downloading {output_file}...\")\n",
    "        files.download(output_file)\n",
    "        print(\"âœ… File download initiated!\")\n",
    "        print(\"ðŸ’¡ Check your browser's download folder for the Excel file\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Output file not found. Make sure to run all previous cells first.\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"â„¹ï¸ Not running in Colab environment\")\n",
    "    if 'output_file' in locals():\n",
    "        print(f\"ðŸ“„ Results saved locally as: {output_file}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Output file not generated. Run previous cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78beec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ System Status & Debugging Information\n",
    "print(\"ðŸ”§ SYSTEM STATUS & DEBUGGING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check LLM availability\n",
    "print(f\"ðŸ¤– LLM Status: {'âœ… Available' if llm_available and llm is not None else 'âŒ Unavailable'}\")\n",
    "\n",
    "# Check if key variables exist\n",
    "variables_to_check = ['openai_client', 'llm', 'embeddings', 'chroma_client', 'product_collection']\n",
    "for var_name in variables_to_check:\n",
    "    if var_name in globals():\n",
    "        status = \"âœ…\" if globals()[var_name] is not None else \"âŒ\"\n",
    "        print(f\"ðŸ“Š {var_name}: {status}\")\n",
    "    else:\n",
    "        print(f\"ðŸ“Š {var_name}: âŒ Not defined\")\n",
    "\n",
    "# Test basic OpenAI connection if possible\n",
    "if 'openai_client' in globals() and openai_client is not None:\n",
    "    try:\n",
    "        test_response = openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": \"test\"}],\n",
    "            max_tokens=5\n",
    "        )\n",
    "        print(f\"ðŸŒ OpenAI API: âœ… Connection successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸŒ OpenAI API: âŒ Connection failed - {e}\")\n",
    "\n",
    "# Check data availability\n",
    "print(f\"ðŸ“§ Emails loaded: {len(emails_df) if 'emails_df' in globals() else 0}\")\n",
    "print(f\"ðŸ“¦ Products loaded: {len(products_df) if 'products_df' in globals() else 0}\")\n",
    "\n",
    "# Classification method used\n",
    "classification_counts = emails_df['classification'].value_counts() if 'emails_df' in globals() and 'classification' in emails_df.columns else {}\n",
    "print(f\"ðŸ“‹ Classification results: {dict(classification_counts)}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Troubleshooting Tips:\")\n",
    "if not llm_available:\n",
    "    print(\"- If LLM is unavailable, the notebook will use keyword-based fallbacks\")\n",
    "    print(\"- To fix LLM issues, ensure you run the 'Section 3: Set Up OpenAI API' cell first\")\n",
    "    print(\"- Check that your API key and endpoint are correct\")\n",
    "print(\"- If you see fallback messages, the system is working but using simpler methods\")\n",
    "print(\"- All core functionality will work even without LLM access\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Notebook execution completed with {'LLM-powered' if llm_available else 'fallback'} processing!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
